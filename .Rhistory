library(piw)
install.packages("SpatialExtremes")
library(SpatialExtremes)
rgev(10, loc=c(1,2), scale=1, shape=0)
rgev(1, loc=c(1,2), scale=1, shape=0)
rgev(2, loc=c(1,2), scale=1, shape=0)
rgev(3, loc=c(1,2), scale=1, shape=0)
rgev(1, loc=c(1,2), scale=1, shape=0)
rgev
log(rexp(10))
log(rexp(1))
c(1,2)-log(rexp(1))
c(1,2)-log(rexp(1))
#'
#' @rdname interactive_text_explanations
#' @importFrom stringi stri_count_words stri_replace_all_fixed
#' @importFrom assertthat assert_that is.string is.count
#' @export
#'
#' @examples
#'
#' \dontrun{
#' library(text2vec)
library(xgboost)
#'
#' data(train_sentences)
#' data(test_sentences)
#'
#' get_matrix <- function(text) {
#'   it <- itoken(text, progressbar = FALSE)
#'   create_dtm(it, vectorizer = hash_vectorizer())
#' }
#'
#' dtm_train = get_matrix(train_sentences$text)
#'
#' xgb_model <- xgb.train(list(max_depth = 7, eta = 0.1, objective = "binary:logistic",
#'                  eval_metric = "error", nthread = 1),
#'                  xgb.DMatrix(dtm_train, label = train_sentences$class.text == "OWNX"),
#'                  nrounds = 50)
#'
#' sentences <- head(test_sentences[test_sentences$class.text == "OWNX", "text"], 1)
#' explainer <- lime(train_sentences$text, xgb_model, get_matrix)
#'
#' # The explainer can now be queried interactively:
#' interactive_text_explanations(explainer)
#' }
interactive_text_explanations <- function(explainer, window_title = "Text model explainer",
title = "Local Interpretable Model-agnostic Explanations",
place_holder = "Put here the text to explain",
minimum_lentgh = 3,
minimum_lentgh_error = "Text provided is too short to be explained (>= 3).",
max_feature_to_select = 20) {
if (!requireNamespace('shiny', quietly = TRUE) || !requireNamespace('shinythemes', quietly = TRUE)) {
stop('shiny and shinythemes are required for this functionality', call. = FALSE)
}
assert_that(is.list(explainer))
assert_that(is.string(window_title))
assert_that(is.string(title))
assert_that(is.string(place_holder))
assert_that(is.count(minimum_lentgh))
assert_that(is.count(max_feature_to_select))
shared_states <- list()
feature_selection_strategy <- local({
strategies <- feature_selection_method()
strategies_clean <- stri_replace_all_fixed(strategies, "_", " ")
names(strategies) <- strategies_clean
as.list(strategies)
})
ui <- shiny::fluidPage(title = window_title,
theme = shinythemes::shinytheme("superhero"),
shiny::titlePanel(title = title),
shiny::hr(),
shiny::sidebarPanel(
shiny::textAreaInput("text_to_explain", label = NULL, resize = "both", placeholder = place_holder, height = "200px"),
shiny::numericInput("number_permutations", label = shiny::h5("Quantity of permutations to generate"), value = 5000, step = 1000),
shiny::selectInput("feature_selection_strategy", label = shiny::h5("Word selection strategies"), choices = feature_selection_strategy, selected = "auto"),
shiny::sliderInput("number_features_to_explain", label = shiny::h5("Number of words to select"), min = 1, max = max_feature_to_select, value = 2, ticks = FALSE)
),
shiny::mainPanel(
text_explanations_output("text_explanations_plot")#,
#plotOutput("feature_weight_plot")
))
# Define server logic for slider examples ----
server <- function(input, output) {
output$text_explanations_plot <- render_text_explanations({
shiny::validate(
shiny::need(stri_count_words(input$text_to_explain) >= minimum_lentgh, message = minimum_lentgh_error)
)
shared_states$explanations <<- explain(input$text_to_explain, explainer, n_labels = 1, n_features = input$number_features_to_explain, feature_select = input$feature_selection_strategy, n_permutations = input$number_permutations)
plot_text_explanations(shared_states$explanations)
})
# output$feature_weight_plot <- renderPlot({
#   validate(
#     need(stri_count_words(input$text_to_explain) >= minimum_lentgh, message = minimum_lentgh_error)
#   )
#   plot_features(shared_states$explanations)
# })
}
shiny::shinyApp(ui, server)
}
library(xgboost)
install.packages("xgboost")
shiny::runApp('workspace/2022/LCPD/r_shiny/lcpd')
library(xgboost)
getwd()
library(shiny)
library(xgboost)
library(dplyr)
df <- read.csv("./LCPD_input2.csv", fileEncoding = "euc-kr")
df <- read.csv("./LCPD_input2.csv", fileEncoding = "euc-kr")
# Define UI for application that draws a histogram
ui <- fluidPage(
# Application title
titlePanel("LCPD"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
numericInput("age_onset", "Age_onset", value=1, min=0, step=0.1),
sliderInput("stage_at_op", "Stage_at_op", value=1, min=1, max=4, step=1),
sliderInput("herring_classification", "Herring_classification", value=1, min=1, max=4, step=1),
sliderInput("catterall", "Catterall", value=1, min=1, max=4, step=1),
numericInput("nsa_pre", "NSA_pre", value=0, step=0.1),
numericInput("nsa_post", "NSA_post", value=0, step=0.1),
numericInput("mp_pre", "MP_pre", value=0, step=0.1),
numericInput("mp_post", "MP_post", value=0, step=0.1),
actionButton("btn", "Run")
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
)
library(shiny)
library(tidyverse)
library(xgboost)
library(dplyr)
library(caret)
library(ROCR)
library(lime)
# Define UI for application that draws a histogram
ui <- fluidPage(
# Application title
titlePanel("LCPD"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
numericInput("age_onset", "Age_onset", value=1, min=0, step=0.1),
sliderInput("stage_at_op", "Stage_at_op", value=1, min=1, max=4, step=1),
sliderInput("herring_classification", "Herring_classification", value=1, min=1, max=4, step=1),
sliderInput("catterall", "Catterall", value=1, min=1, max=4, step=1),
numericInput("nsa_pre", "NSA_pre", value=0, step=0.1),
numericInput("nsa_post", "NSA_post", value=0, step=0.1),
numericInput("mp_pre", "MP_pre", value=0, step=0.1),
numericInput("mp_post", "MP_post", value=0, step=0.1),
actionButton("btn", "Run")
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
)
# Define server logic required to draw a histogram
server <- function(input, output) {
df <- read.csv("./LCPD_input2.csv", fileEncoding = "euc-kr")
set.seed(12)
x.train.idx <- sample(x=nrow(df), size = nrow(df)*0.8, replace = F)
X <- df %>% select(Male:Catterall)
y <- df %>% select(Stulberg)
X.train <- X[x.train.idx, ]
bst <- xgb.load('xgb.model')
explainer <- lime(X.train, bst)
output$distPlot <- renderPlot({
explanation <-  explain(X.test[4:4,], explainer, n_labels=3, n_features = 5)
plot_features(explanation)
})
}
# Run the application
shinyApp(ui = ui, server = server)
# Define UI for application that draws a histogram
ui <- fluidPage(
# Application title
titlePanel("LCPD"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
numericInput("age_onset", "Age_onset", value=1, min=0, step=0.1),
sliderInput("stage_at_op", "Stage_at_op", value=1, min=1, max=4, step=1),
sliderInput("herring_classification", "Herring_classification", value=1, min=1, max=4, step=1),
sliderInput("catterall", "Catterall", value=1, min=1, max=4, step=1),
numericInput("nsa_pre", "NSA_pre", value=0, step=0.1),
numericInput("nsa_post", "NSA_post", value=0, step=0.1),
numericInput("mp_pre", "MP_pre", value=0, step=0.1),
numericInput("mp_post", "MP_post", value=0, step=0.1),
actionButton("btn", "Run")
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
)
library(shiny)
library(tidyverse)
library(xgboost)
library(dplyr)
library(caret)
library(ROCR)
library(lime)
# Define UI for application that draws a histogram
ui <- fluidPage(
# Application title
titlePanel("LCPD"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
numericInput("age_onset", "Age_onset", value=1, min=0, step=0.1),
sliderInput("stage_at_op", "Stage_at_op", value=1, min=1, max=4, step=1),
sliderInput("herring_classification", "Herring_classification", value=1, min=1, max=4, step=1),
sliderInput("catterall", "Catterall", value=1, min=1, max=4, step=1),
numericInput("nsa_pre", "NSA_pre", value=0, step=0.1),
numericInput("nsa_post", "NSA_post", value=0, step=0.1),
numericInput("mp_pre", "MP_pre", value=0, step=0.1),
numericInput("mp_post", "MP_post", value=0, step=0.1),
actionButton("btn", "Run")
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
)
# Define server logic required to draw a histogram
server <- function(input, output) {
df <- read.csv("./LCPD_input2.csv", fileEncoding = "euc-kr")
set.seed(12)
x.train.idx <- sample(x=nrow(df), size = nrow(df)*0.8, replace = F)
X <- df %>% select(Male:Catterall)
y <- df %>% select(Stulberg)
X.train <- X[x.train.idx, ]
bst <- xgb.load('xgb.model')
explainer <- lime(X.train, bst)
output$distPlot <- renderPlot({
explanation <-  explain(X.test[4:4,], explainer, n_labels=3, n_features = 5)
plot_features(explanation)
})
}
# Run the application
shinyApp(ui = ui, server = server)
setwd("~/workspace/projects/pi-weights-rpackage/")
install.packages("distributions/piw_0.1.0.tar.gz", repos = NULL, type="source")
# Setting -----------------------------------------------------------------
library(piw)
# Setting -----------------------------------------------------------------
library(piw)
obs.file.path <-
"not_importing_data/2020.10.05/OBS.rds"
# model 자료 경로
histDir.bc <- "not_importing_data/2020.10.05/historical"
s245Dir.bc <- "not_importing_data/2020.10.05/ssp245"
s370Dir.bc <- "not_importing_data/2020.10.05/ssp370"
s585Dir.bc <- "not_importing_data/2020.10.05/ssp585"
histDir <- "not_importing_data/2020.10.07/CMIP6_EastAsia_variables_nbc2/historical"
s245Dir <- "not_importing_data/2020.10.07/CMIP6_EastAsia_variables_nbc2/ssp245"
s370Dir <- "not_importing_data/2020.10.07/CMIP6_EastAsia_variables_nbc2/ssp370"
s585Dir <- "not_importing_data/2020.10.07/CMIP6_EastAsia_variables_nbc2/ssp585"
# 그림 저장 경로
eps.save.path <- "not_importing_output/eps/"
pdf.save.path <- "not_importing_output/pdf/"
png.save.path <- "not_importing_output/png/"
# Set period : RFA
filter.period <- 1973:2010
# set Return Level to be considered
rt.lv <- c(2, 5, 10, 20, 30, 50, 100)
vars <- c("AMP1","AMP5","ATP","AMCWD","AMCDD")
obs <- readata.fromFilePath(obs.file.path, filter.period, variable_names = vars, rfa9 = T)
his    <- readata.fromDirPath(histDir   , filter.period, variable_names = vars, rfa9 = T)
his.bc <- readata.fromDirPath(histDir.bc, filter.period, variable_names = vars, rfa9 = T)
library(lmom)
# Parameter estimation Functions by L-moments
pfns <- list(pelgev, pelgev, pelnor, pelgev, pelgev)
# Quantile Functions
qfns <- list(quagev, quagev, quanor, quagev, quagev)
obs.rtlv <- rtlv.multi.var(obs, pfns, qfns)
his.rtlv <- rtlv.multi.var(his, pfns, qfns)
his.rtlv.bc <- rtlv.multi.var(his, pfns, qfns)
obs.tilde <- tilde.normalization(obs, his, target.rtlv = obs.rtlv)
his.tilde <- tilde.normalization(obs, his, target.rtlv = his.rtlv)
## Sigma.D
res.sigma.d <- calc.sigma.d(ref = obs.tilde,
model = his.tilde,
simul.N = 10000,
random.seed = 197079,
significance.level = 0.05,
candi.sigma.d = seq(1.0, 0.01, -0.01))
sigma.D <- res.sigma.d$sigma.D
## Weights
perf.weight.res <- calc.performance.weights(ref=obs.tilde, model = his.tilde, sigma.D)
perf.weight <- perf.weight.res$weight.df
# Find Optimal Sigma.S from Entropy Approach
system.time({
res.sigma.s <-
calc.sigma.s(hisDir = histDir,
sceDir = c(s245Dir,s370Dir,s585Dir),
ref.period = 1850:2010,
sce.period = 2015:2100,
variableNames = vars,
candi.sigma.s = seq(0.1, 1, 0.05),
filter.grid = NULL)
})
sigma.s <- res.sigma.s$sigma.S$sigma.s
# >> Main : Figure 2 ---------------------------------------------------------
# Visualization
plot.sigma.s.res(res.sigma.s)
## perf-weights 와는 다르게 모델별 ind-weights 는 전 지역에 대해 동일한 값임.
## Weights
indep.weight <- res.sigma.s$weights
pi.weight <- calc.pi.weight(perf.weight_ = perf.weight, indep.weight_ = indep.weight)
# >> Main : Figure 5 ------------------------------------------------------
## plot
plot.weights(perf.weight, indep.weight, pi.weight) +
ggplot2::ggtitle(as.expression(bquote(sigma[S] ~ "=" ~ .(sprintf("%.2f",sigma.s)) ~ "," ~ sigma[D] ~ "=" ~ .(sprintf("%.2f",sigma.D )))))
kr.grids <- c(393:394,443:444,494:497,552:556,616:620,672:676,
729:732,786:791,844:849,900:904,950:951)
sce.ensembled.bc <-
ensemble.sce(refDir = obs.file.path,
refPeriod = 1973:2010,
sceDir = c(s245Dir.bc, s370Dir.bc, s585Dir.bc),
sceName = c("s245","s370","s585"),
scePeriod = list(p1=2021:2050,p2=2046:2075,p3=2071:2100),
variableNames = c("AMP1"),
pfn = list(lmom::pelgev),
qfn = list(lmom::quagev),
weight = pi.weight,
rt.lv = c(2, 5, 10, 20, 30, 50, 100, 150, 200),
ref.filter.grid = kr.grids,
sce.filter.grid = kr.grids,
weight.filter.grid = kr.grids,
rfa9 = TRUE
)
# 한반도 지역의 obs : return level 계산
obs <- readata.fromFilePath(obs.file.path, 1973:2010, "AMP1", kr.grids, rfa9=TRUE)
obs.rtlv <- rtlv.multi.var(obs, list(lmom::pelgev), list(lmom::quagev))
# 한반도 지역 his : return level 계산
his <- readata.fromDirPath(histDir, 1973:2010, "AMP1", kr.grids, rfa9 = TRUE)
his.rtlv <- rtlv.multi.var(his, list(lmom::pelgev), list(lmom::quagev))
# 상자그림에 보여줄 his : return level의 평균 계산
his.ensembled <-
lapply(his.rtlv, function(x){
weighted.sum(rtlv.list = x, weights = "equal")
})
# >> Main : Figure 7 ------------------------------------
# 20y return level 상자그림 그리기
rtlv.boxplot(ref.rtlv = obs.rtlv,
his.rtlv.ensembled = his.ensembled,
sce.rtlv.ensembled = sce.ensembled.bc$return.level,
variable.name = "AMP1",
rt.name = "rt20",
ylim=c(50, 500),
label=c("SSP2-4.5","SSP3-7.0","SSP5-8.5"),
label.y.coord = 500,
label.x.coord = c(4,7,10),
axis.x.label=c("OBS","HIS(NBC)","P1","P2","P3","P1","P2","P3","P1","P2","P3"),
y.label = "Return Level",
calibrate.text.size=-3)
# >> SM : Figure S 3 ------------------------------------
# 50y return level 상자그림 그리기
rtlv.boxplot(ref.rtlv = obs.rtlv,
his.rtlv.ensembled = his.ensembled,
sce.rtlv.ensembled = sce.ensembled.bc$return.level,
variable.name = "AMP1",
rt.name = "rt50",
ylim=c(50, 500),
label=c("SSP2-4.5","SSP3-7.0","SSP5-8.5"),
label.y.coord = 500,
label.x.coord = c(4,7,10),
axis.x.label=c("OBS","HIS(NBC)","P1","P2","P3","P1","P2","P3","P1","P2","P3"),
y.label = "Return Level(50y)",
calibrate.text.size=-3)
rtpd.bplot <-
rtpd.boxplot(ensemble.sce.obj = sce.ensembled.bc,
var.name = "AMP1",
rtlv = c("rt20","rt50"),
facet.label = c("rt20"="20-year","rt50"="50-year"),
axis.x.names = c("P1","P2","P3","P1","P2","P3","P1","P2","P3"),
calibrate.text.size=-1)
# 라벨 추가
lb <- data.frame(x=c(2,5,8,2,5,8),
y=c(rep(65,3), rep(65,3)),
label=c("SSP2-4.5","SSP3-7.0","SSP5-8.5","SSP2-4.5","SSP3-7.0","SSP5-8.5"),
variable = c(rep("rt20",3), rep("rt50", 3)))
# >> Main : Figure 9 ------------------------------------------------------
rtpd.bplot +
ggplot2::scale_y_continuous(limits = c(3, 65), breaks = seq(0, 65, by = 10))+
ggplot2::geom_label(data=lb, ggplot2::aes(x=x, y=y, label=label, group=variable), inherit.aes = F, size=7/2.2)
# 분산 계산, 논문에서는 n.boots = 500 으로 했음.
var.rtlv.pi <- var.rtlv(sce.ensembled.bc, n.boots = 500, random.seed = 121212)
var.rtlv.pi
# >> Main : Figure 14 ------------------------------------------------------
library(ggpubr)
my.col <- RColorBrewer::brewer.pal(3, 'Set1')
my.col <- c(my.col[1], 'black', my.col[3])
ggpubr::ggarrange(
var.scatter.plot(var.rtlv.pi, "AMP1", "rt20", "total")+ ggplot2::scale_color_manual(values = my.col),
var.scatter.plot(var.rtlv.pi, "AMP1", "rt20", "vbm")  + ggplot2::scale_color_manual(values = my.col),
var.scatter.plot(var.rtlv.pi, "AMP1", "rt20", "vwm")  + ggplot2::scale_color_manual(values = my.col),
nrow = 3, common.legend = TRUE, legend='top'
)
# >> Main : Table 4 -------------------------------------------------------
bss.table(var.rtlv.obj = var.rtlv.pi, var.name="AMP1", rtlv = 'rt20')
# Exceedence Probability --------------------------------------------------
kr.grids <- c(393:394,443:444,494:497,552:556,616:620,672:676,
729:732,786:791,844:849,900:904,950:951)
z_ = c(seq(50, 500, 50), 750, 1000)
# 한국 격자에 대한 가중값만 뽑아서 list 형태로 변환
pi.weight.list <-
split(x = pi.weight %>% dplyr::select(-model), f = pi.weight$model) %>%
lapply(function(x){
x %>% dplyr::select(kr.grids) %>% t()
})
# AMP1 자료만 사용, RFA 적용하지 않은 채로, 한국 격자에 대해서만
obs <- readata.fromFilePath(obs.file.path,
filter.period = 1973:2010,
variable_names = 'AMP1',
filter.grid = kr.grids,
rfa9 = F)
# 확률 계산
obs.exc.prob <-
exceedence.prob.multi.var(data.obj = obs,
pfns = list(lmom::pelgev),
cdfns = list(lmom::cdfgev),
z = z_)
# AMP1 자료만 사용, RFA 적용하지 않은 채로, 한국 격자에 대해서만
his.bc <- readata.fromDirPath(histDir.bc,
filter.period = 1973:2010,
variable_names = 'AMP1',
filter.grid = kr.grids,
rfa9 = F)
# historical 자료 확률 계산하고 앙상블
his.bc.exc.prob.ensembled <-
exceedence.prob.multi.var(data.obj = his.bc,
pfns = list(lmom::pelgev),
cdfns = list(lmom::cdfgev), z = z_) %>%
lapply(function(p.var.model){
weighted.sum(p.var.model, pi.weight.list)
})
# scenario 자료,  한국 격자에 대해서만, RFA 하지 않음.
# 자료 읽고 바로 확률 계산해서 앙상블 적용
sce.bc.exc.prob.ensembled <-
## 미래 시나리오 디렉토리별
lapply(c(s245Dir.bc, s370Dir.bc, s585Dir.bc), function(sce){
## 미래 시나리오 기간별
lapply(list(p1=2021:2050,p2=2046:2075,p3=2071:2100), function(p){
# 데이터 읽어서
data <- readata.fromDirPath(sce, p, variable_names = 'AMP1', filter.grid = kr.grids, rfa9 = F)
# exc prob 계산하고
exc.prob <-
exceedence.prob.multi.var(data.obj = data,
pfns = list(lmom::pelgev),
cdfns = list(lmom::cdfgev),
z = z_)
# 앙상블
lapply(exc.prob, function(p.var.model){
weighted.sum(p.var.model, pi.weight.list)
})
})
}) %>% `names<-`(c('s245','s370','s585'))
# exceedence probability 결과 모두 합치기
exc.prob.all <-
rbind(
# obs 그림을 p1, p2, p3 에 똑같이 넣기 위해..
reshape2::melt(obs.exc.prob) %>%
`colnames<-`(c('loc','z','value','var')) %>%
dplyr::mutate(period='p1', sce='obs'),
reshape2::melt(obs.exc.prob) %>%
`colnames<-`(c('loc','z','value','var')) %>%
dplyr::mutate(period='p2', sce='obs'),
reshape2::melt(obs.exc.prob) %>%
`colnames<-`(c('loc','z','value','var')) %>%
dplyr::mutate(period='p3', sce='obs'),
# his 결과
reshape2::melt(his.bc.exc.prob.ensembled) %>%
`colnames<-`(c('loc','z','value','var')) %>%
dplyr::mutate(period='p0', sce='hist'),
# sce 결과
reshape2::melt(sce.bc.exc.prob.ensembled) %>%
`colnames<-`(c('loc','z','value','var','period','sce'))
) %>% dplyr::mutate(z.n = as.numeric(gsub(pattern = 'z', replacement = '', x = z)))
# 모든 격자에 대해 median 값 계산
exc.prob.all.med <- exc.prob.all %>%
dplyr::select(-loc, -z) %>%
dplyr::group_by(var, sce, period, z.n) %>%
tidyr::nest() %>%
dplyr::mutate(med=purrr::map(data, ~median(.$value))) %>%
tidyr::unnest(med)
# >> SM : Figure S 6 ------------------------------------
exc.prob.all.med %>%
dplyr::filter(var == "AMP1", sce %in% c("obs", "s245", "s370", "s585"), z.n <= 300) %>%
ggplot2::ggplot(mapping = ggplot2::aes(x = z.n, y = med, colour=sce)) +
ggplot2::geom_line() +
ggplot2::scale_x_continuous(breaks = z_[z_<=300])+
ggplot2::facet_grid(~period) +
ggplot2::theme_bw() +
ggplot2::ylab("Probability") +
ggplot2::xlab("AMP1")+
ggplot2::theme(legend.position = "top",
legend.title    = ggplot2::element_blank())
# >> SM : Table S3 -----------------------------------------------------------
# Return Level stats
rtlv.table(return.level.obj = sce.ensembled.bc$return.level,
rt.lv = c('rt20', 'rt50'))
